# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R_xno2ImLpvz3Yjlv7HXh4tA6TADT-R4
"""

## Major Libraries
import numpy as np
import pandas as pd
import os
## sklearn -- for pipeline and preprocessing
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline, FeatureUnion
#pip install sklearn_features
from sklearn_features.transformers import DataFrameSelector


## Read the CSV file using pandas
data = pd.read_csv('2022-2023 Football Player Stats.csv',   sep = ';', encoding = 'ISO-8859-1')
pd.set_option('display.max_columns', None)

## Try to make some Feature Engineering --> Feature Extraction --> Add the new column to the main DF
data = data.drop(['Rk', 'Born', 'PasAtt', 'Crs' , 'Nation'], axis = 1)

df_data = pd.DataFrame()
df_data['Player'] = data['Player']
#df_data['Nation'] = data['Nation']
df_data['Pos'] = data['Pos']
df_data['Squad'] = data['Squad']
df_data['Comp'] = data['Comp']
df_data['Age'] = data['Age']
df_data['MP'] = data['MP']
df_data['G/90'] = data['Goals']
#df_data['G/Sh'] = data['G/Sh']
#df_data['PKGoals'] = ((data['ShoPK'] * data['Min']) / 90).round(0).astype(int)
#df_data['PKAttempted'] = ((data['PKatt'] * data['Min']) / 90).round(0).astype(int)
#df_data['Goals'] = ((data['Goals'] * data['Min']) / 90).round(0).astype(int)
df_data['Pass'] = ((data['PasTotAtt'] * data['Min']) / 90).round(0).astype(int)
df_data['PassCompleted'] = ((data['PasTotCmp'] * data['Min']) / 90).round(0).astype(int)
df_data['PassComp%'] = ((df_data['PassCompleted'] / df_data['Pass']) * 100).round(2)
df_data['Assist'] = ((data['Assists'] * data['Min']) / 90).round(0).astype(int)
df_data['Cross'] = ((data['PasCrs'] * data['Min']) / 90).round(0).astype(int)
df_data['CrossCompleted'] = ((data['CrsPA'] * data['Min']) / 90).round(0).astype(int)
df_data['CrossComp%'] = ((df_data['CrossCompleted'] / df_data['Cross']) * 100).round(2)
df_data['Tackle_Won'] = ((data['TklWon'] * data['Min']) / 90).round(0).astype(int)
#df_data['SucDribble'] = ((data['DriSucc'] * data['Min']) / 90).round(0).astype(int)
#df_data['Dribble'] = ((data['DriAtt'] * data['Min']) / 90).round(0).astype(int)
#df_data['DribbleComp%'] = ((df_data['SucDribble'] / df_data['Dribble']) * 100).round(2)
#df_data['YCards'] = ((data['CrdY'] * data['Min']) / 90).round(0).astype(int)
#df_data['RCards'] = ((data['CrdR'] * data['Min']) / 90).round(0).astype(int)
#df_data['Fls'] = ((data['Fls'] * data['Min']) / 90).round(0).astype(int)
#df_data['Fld'] = ((data['Fld'] * data['Min']) / 90).round(0).astype(int)
#df_data['OGoals'] = ((data['OG'] * data['Min']) / 90).round(0).astype(int)
df_data['AerWon'] = ((data['AerWon'] * data['Min']) / 90).round(0).astype(int)
df_data['AerLost'] = ((data['AerLost'] * data['Min']) / 90).round(0).astype(int)
df_data['AerWon%'] = ((data['AerWon'] / (data['AerWon'] + data['AerLost'])) * 100).round(2)

import numpy as np
new_data = df_data[ (df_data['Squad'] != 'Barcelona') & (df_data['Squad'] !='Real Madrid')].index
df_data.drop(new_data, inplace=True)
df_data.drop([1629 , 1978 , 2452 ], axis=0, inplace=True)
df_data["Squad"].value_counts()
out1 = np.array([28 ,5 , 7 , 70 ,30 ,  5 , 40 , 6, 30 , 30  , 35 , 60 , 100 , 60 , 50 , 40 , 3 , 90 , 12 , 60 , 120 , 25 , 35 , 60 , 15 , 50 , 12 , 60 , 5 , 100 , 40 , 5 , 2.5 , 50 , 70 , 80 , 10, 6 , 90 , 35 , 18  , 9 , 8 , 8])

df_data['Market value / M'] = out1
X = df_data[[ 'G/90','Assist', 'Pass' , 'PassCompleted'  , 'Tackle_Won' , 'AerWon' , 'Cross' , 'CrossCompleted' ,'AerLost'  ]]
y= df_data['Market value / M']
X['G/90'].replace(0,X['G/90'].mean())
X['Assist'].replace(0,X['Assist'].mean())
X['Pass'].replace(0,X['Pass'].mean())
X['PassCompleted'].replace(0,X['PassCompleted'].mean())
X['Tackle_Won'].replace(0,X['Tackle_Won'].mean())
X['AerWon'].replace(0,X['AerWon'].mean())
X['AerLost'].replace(0,X['AerLost'].mean())
X['Cross'].replace(0,X['Cross'].mean())
X['CrossCompleted'].replace(0,X['CrossCompleted'].mean())


## the same Random_state (take care)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)

## Separete the columns according to type (numerical or categorical)

num_cols = [col for col in X_train.columns if X_train[col].dtype in ['float32', 'float64', 'int32', 'int64']]
categ_cols = [col for col in X_train.columns if X_train[col].dtype not in ['float32', 'float64', 'int32', 'int64']]

## We can get much much easier like the following
## numerical pipeline
num_pipeline = Pipeline([
                        ('selector', DataFrameSelector(num_cols)),    ## select only these columns
                        ('imputer', SimpleImputer(strategy='median')),
                        ('scaler', StandardScaler())
                        ])

## categorical pipeline

## concatenate both two pipelines


X_train= num_pipeline.fit_transform(X_train) ## fit

def preprocess_new(X_new):
    ''' This Function tries to process the new instances before predicted using Model
    Args:
    *****
        (X_new: 2D array) --> The Features in the same order
                ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 
                 'population', 'households', 'median_income', 'ocean_proximity']
        All Featutes are Numerical, except the last one is Categorical.
        
     Returns:
     *******
         Preprocessed Features ready to make inference by the Model
    '''
    return num_pipeline.transform(X_new)